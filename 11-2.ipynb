{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cpuman7/tensorflow_example/blob/master/11-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBFD6J98njGx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "outputId": "219b80a7-e406-458a-b61b-dcd2ef0abb94"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "tf.set_random_seed(777)\n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "learning_rate = 0.001  #학습률\n",
        "training_epochs = 15  #epoch: 15\n",
        "batch_size = 100  #배치 사이즈: 100\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32)  #drop out  수치, 학습 시 0.5~0.7, 검증 시 1\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "X_img = tf.reshape(X, [-1, 28, 28, 1])  # 28*28*1사이즈로 reshape\n",
        "Y = tf.placeholder(tf.float32, [None, 10])  # 출력 갯수 0~9로 10개\n",
        "\n",
        "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))  #filter size: 3(X)*3(Y)*1(C), fiter 갯수: 32, 표준편차: 0.01\n",
        "L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1], padding='SAME')  #stride: 1*1, strides의 [0]과 [3]은 무조건 1\n",
        "#Image Shape:(?, 28, 28, 32)\n",
        "L1 = tf.nn.relu(L1)  #활성화 함수: ReLU\n",
        "#Image Shape:(?, 28, 28, 32)\n",
        "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides = [1, 2, 2, 1], padding='SAME')  #MaxPooling, kernel size: 2*2*1, stride: 2*2*1\n",
        "#Image Shape:(?, 14, 14, 32)\n",
        "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)  #DropOut\n",
        "#Image Shape:(?, 14, 14, 32)\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))  #filter size: 3*3*32(Layer1에서 32개의 filter로 생성했기 때문), filter 갯수: 64\n",
        "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')  #stride: 1*1\n",
        "#Image Shape:(?, 14, 14, 64)\n",
        "L2 = tf.nn.relu(L2)  #활성화 함수: ReLU\n",
        "#Image Shape:(?, 14, 14, 64)\n",
        "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')  #MaxPooling, kernel size: 2*2*1, stride: 2*2*1\n",
        "#Image Shape:(?, 7, 7, 64)\n",
        "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)  #DropOut\n",
        "#Image Shape:(?, 7, 7, 64)\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))  #filter size: 3*3*64(Layer2에서 64개의 filter로 생성했기 때문),filter 갯수: 128\n",
        "L3 = tf.nn.conv2d(L2, W3, strides = [1, 1, 1, 1], padding='SAME')  #stride: 1*1\n",
        "#Image Shape:(?, 7, 7, 128)\n",
        "L3 = tf.nn.relu(L3)  #활성화 함수: ReLU\n",
        "#Image Shape:(?, 7, 7, 128)\n",
        "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')  #MaxPooling, kernel size: 2*2*1, stride: 2*2*1\n",
        "#Image Shape:(?, 4, 4, 128)\n",
        "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)  #DropOut\n",
        "#Image Shape:(?, 4, 4, 128)\n",
        "L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
        "#Image Shape:(?, 2048)\n",
        "\n",
        "W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625], initializer=tf.contrib.layers.xavier_initializer())  #Input size: 2048, Output size: 625, Initializer: Xavier\n",
        "b4 = tf.Variable(tf.random_normal([625]))\n",
        "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)  #활성화함수: ReLU\n",
        "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)  #DropOut\n",
        "\n",
        "W5 = tf.get_variable(\"W5\", shape=[625, 10], initializer=tf.contrib.layers.xavier_initializer())  #Input size: 625, Output size: 10, Initializer: Xavier\n",
        "b5 = tf.Variable(tf.random_normal([10]))\n",
        "logits = tf.matmul(L4, W5) + b5\n",
        "\n",
        "#Cost Function\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)  #Optimizer: Adam\n",
        "\n",
        "#Initialize\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "#Training\n",
        "print('Learning started')\n",
        "for epoch in range(training_epochs):\n",
        "  avg_cost = 0\n",
        "  total_batch = int(mnist.train.num_examples / batch_size)\n",
        "  \n",
        "  for i in range(total_batch):\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "    feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
        "    c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
        "    avg_cost += c / total_batch\n",
        "    \n",
        "  print('Epoch: ', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n",
        "  \n",
        "print('Learning Finished')\n",
        "\n",
        "#Check Accuracy\n",
        "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
        "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
        "\n",
        "# Get one and predict\n",
        "r = random.randint(0, mnist.test.num_examples - 1)\n",
        "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
        "print(\"Prediction: \", sess.run(\n",
        "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
        "\n",
        "plt.imshow(mnist.test.images[r:r + 1].\n",
        "reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0819 09:01:50.229657 139979963922304 deprecation.py:323] From <ipython-input-19-030012b00c7c>:65: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Learning started\n",
            "Epoch:  0001 cost =  0.365652760\n",
            "Epoch:  0002 cost =  0.102024115\n",
            "Epoch:  0003 cost =  0.073605365\n",
            "Epoch:  0004 cost =  0.060561172\n",
            "Epoch:  0005 cost =  0.050102010\n",
            "Epoch:  0006 cost =  0.045606690\n",
            "Epoch:  0007 cost =  0.043939578\n",
            "Epoch:  0008 cost =  0.038386950\n",
            "Epoch:  0009 cost =  0.035203932\n",
            "Epoch:  0010 cost =  0.035286386\n",
            "Epoch:  0011 cost =  0.029418148\n",
            "Epoch:  0012 cost =  0.030336113\n",
            "Epoch:  0013 cost =  0.028220017\n",
            "Epoch:  0014 cost =  0.025865923\n",
            "Epoch:  0015 cost =  0.025325084\n",
            "Learning Finished\n",
            "Accuracy: 0.9938\n",
            "Label:  [8]\n",
            "Prediction:  [8]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADnhJREFUeJzt3X2MVGWWx/HfEWf8g0FjQ0sIoD0i\nMaLJwloha0bNbHQmjEFl/pCAhuAbjAaNmEnU+LYk/qFRZkbFzWjP0g5MeNs4EEk0u+OSjQbdTCwN\nvjCwK5omAwG6iRoZiYFmzv7RF9Nq36eaulV1C873k3S66p771D1T449bVU/1fczdBSCe08puAEA5\nCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaBOb+XBxo0b511dXa08JBBKb2+vDh48aCPZt1D4\nzWyWpGckjZL0b+7+RGr/rq4uVavVIocEkFCpVEa8b90v+81slKR/lfQzSdMkzTezafU+HoDWKvKe\nf6akXe7+ibsfkbRe0vWNaQtAsxUJ/0RJfx1yf0+27RvMbLGZVc2s2t/fX+BwABqp6Z/2u3u3u1fc\nvdLZ2dnswwEYoSLh3ytp8pD7k7JtAE4CRcL/tqSpZvZDM/u+pHmSNjemLQDNVvdUn7sPmNldkv5T\ng1N9Pe6+vWGdAWiqQvP87v6qpFcb1AuAFuLrvUBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8\nQFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii\n/EBQhB8IivADQRF+ICjCDwRVaJVeM+uVdEjSMUkD7l5pRFM4MTt37sytzZs3Lzn28OHDyfpVV12V\nrI8ZMyZZf/LJJ5N1lKdQ+DP/7O4HG/A4AFqIl/1AUEXD75L+ZGbvmNniRjQEoDWKvuy/3N33mtk5\nkl4zs53u/sbQHbJ/FBZL0rnnnlvwcAAapdCZ3933Zr/7JG2SNHOYfbrdveLulc7OziKHA9BAdYff\nzEab2ZjjtyX9VNKHjWoMQHMVedk/XtImMzv+OGvd/T8a0hWApqs7/O7+iaR/aGAvyLFly5Zkfc6c\nObm1L7/8stCxd+3aVWj8lVdemVubPXt2occ+dOhQsl7rOwjRMdUHBEX4gaAIPxAU4QeCIvxAUIQf\nCKoRf9WHgnbs2JGsp6bypPR03qxZs5JjX3rppWS9v78/Wb/llluS9ddffz23Vmuqr1ZvN910U7J+\n880359ZeeOGF5NgIOPMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFDM87eB5cuXJ+u1/iz30Ucfza09\n8sgjybGjRo1K1s8777xkfe7cucn6kiVLcmv33HNPcuzAwECyfvTo0WR948aNuTXm+TnzA2ERfiAo\nwg8ERfiBoAg/EBThB4Ii/EBQzPO3gbFjxxYaf++99+bWas3jF1VrCe9p06bl1s4888zk2BUrVtTV\n03G33nprofGnOs78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUzXl+M+uRNFtSn7tfkm3rkLRBUpek\nXklz3f2z5rV5ajvjjDMKjU9dG/+6664r9Ni1vPXWW8n66NGjc2uXXXZZcmyt9QwuvPDCZP3+++9P\n1qMbyZn/95K+vfLDA5K2uPtUSVuy+wBOIjXD7+5vSPr0W5uvl7Qqu71KUnpJGQBtp973/OPdfV92\ne7+k8Q3qB0CLFP7Az91dkufVzWyxmVXNrFpr3TcArVNv+A+Y2QRJyn735e3o7t3uXnH3SmdnZ52H\nA9Bo9YZ/s6SF2e2Fkl5uTDsAWqVm+M1snaT/kXShme0xs9skPSHpJ2b2kaSrs/sATiI2+Ja9NSqV\niler1ZYd72Rx8ODBZP38889P1idOnJhbe/PNN5NjOzo6kvXDhw8n67fffnuyvn79+mQ9ZdKkScn6\nhg0bkvVa3yM4FVUqFVWrVRvJvnzDDwiK8ANBEX4gKMIPBEX4gaAIPxAUl+5uA+PGjUvW77jjjmQ9\ntcT3fffdlxz79NNPJ+vvvfdesn7xxRcn60U8/PDDyXrEqbxG4swPBEX4gaAIPxAU4QeCIvxAUIQf\nCIrwA0Exz38SWLZsWbK+e/fu3FpPT09y7Mcff5ysd3V1Jetr165N1lOXJb/77ruTY1liu7k48wNB\nEX4gKMIPBEX4gaAIPxAU4QeCIvxAUFy6+xTQ15e7YJIuuuii5NjPPiu2snqt5cWfffbZ3NqiRYsK\nHRvfxaW7AdRE+IGgCD8QFOEHgiL8QFCEHwiK8ANB1fx7fjPrkTRbUp+7X5JtWyZpkaT+bLcH3f3V\nZjWJtHPOOSe3Vuua/48//nihY9e6tj5z+e1rJGf+30uaNcz237j79OyH4AMnmZrhd/c3JH3agl4A\ntFCR9/x3mdn7ZtZjZmc3rCMALVFv+H8raYqk6ZL2SfpV3o5mttjMqmZW7e/vz9sNQIvVFX53P+Du\nx9z975J+J2lmYt9ud6+4e6Wzs7PePgE0WF3hN7MJQ+7+XNKHjWkHQKuMZKpvnaQfSxpnZnsk/Yuk\nH5vZdEkuqVfSL5rYI4AmqBl+d58/zOaVTegFddq6dWtu7cUXX2zqsdevX5+s33nnnbm1jo6ORreD\nE8A3/ICgCD8QFOEHgiL8QFCEHwiK8ANBsUT3SeCLL75I1lNLWe/fvz85durUqcn6kSNHkvXt27cn\n66tXr86tLV26NDkWzcWZHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCYp7/JNDd3Z2s79q1K7d2wQUX\nJMdu2rQpWf/qq6+S9auvvjpZf+WVV3JrzPOXizM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFPH8b\nOHbsWLK+fPnyuh97zZo1yfq0adOS9VrXA/j888+T9d27d+fWav3vHjVqVLKOYjjzA0ERfiAowg8E\nRfiBoAg/EBThB4Ii/EBQNef5zWyypNWSxktySd3u/oyZdUjaIKlLUq+kue7+WfNaPXU9//zzyXpf\nX1+yfumll+bWZsyYUVdPxx09erTQ+NS1BtauXZscu2DBgkLHRtpIzvwDkn7p7tMk/ZOkJWY2TdID\nkra4+1RJW7L7AE4SNcPv7vvc/d3s9iFJOyRNlHS9pFXZbqskzWlWkwAa74Te85tZl6QZkv4saby7\n78tK+zX4tgDASWLE4TezH0j6o6Sl7v6NxePc3TX4ecBw4xabWdXMqv39/YWaBdA4Iwq/mX1Pg8Ff\n4+4bs80HzGxCVp8gadhPpdy9290r7l7p7OxsRM8AGqBm+M3MJK2UtMPdfz2ktFnSwuz2QkkvN749\nAM0ykj/p/ZGkBZI+MLNt2bYHJT0h6d/N7DZJuyXNbU6Lp75afzZby/z583Nrp5+e/r94YGAgWX/q\nqafq6um4sWPH5tauuOKKQo+NYmqG3923SrKc8lWNbQdAq/ANPyAowg8ERfiBoAg/EBThB4Ii/EBQ\nXLr7FNDb25tbW7duXXLsY489lqzv3Lmznpa+9tBDD+XWurq6Cj02iuHMDwRF+IGgCD8QFOEHgiL8\nQFCEHwiK8ANBMc/fBk47Lf1vcK2lqp977rnc2ooVK5Jjp0yZkqzXcu211ybrN954Y6HHR/Nw5geC\nIvxAUIQfCIrwA0ERfiAowg8ERfiBoGxwpa3WqFQqXq1WW3a8U8Xhw4eT9Z6entzaypUrk2OXLFmS\nrJ911lnJ+g033JCso7UqlYqq1Wrepfa/gTM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRVc57fzCZL\nWi1pvCSX1O3uz5jZMkmLJPVnuz7o7q+mHot5fqC5TmSefyQX8xiQ9Et3f9fMxkh6x8xey2q/cffl\n9TYKoDw1w+/u+yTty24fMrMdkiY2uzEAzXVC7/nNrEvSDEl/zjbdZWbvm1mPmZ2dM2axmVXNrNrf\n3z/cLgBKMOLwm9kPJP1R0lJ3/0LSbyVNkTRdg68MfjXcOHfvdveKu1c6Ozsb0DKARhhR+M3sexoM\n/hp33yhJ7n7A3Y+5+98l/U7SzOa1CaDRaobfzEzSSkk73P3XQ7ZPGLLbzyV92Pj2ADTLSD7t/5Gk\nBZI+MLNt2bYHJc03s+kanP7rlfSLpnQIoClG8mn/VknDzRsm5/QBtDe+4QcERfiBoAg/EBThB4Ii\n/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiqpUt0m1m/pN1DNo2TdLBlDZyYdu2t\nXfuS6K1ejeztPHcf0fXyWhr+7xzcrOruldIaSGjX3tq1L4ne6lVWb7zsB4Ii/EBQZYe/u+Tjp7Rr\nb+3al0Rv9Sqlt1Lf8wMoT9lnfgAlKSX8ZjbLzP7XzHaZ2QNl9JDHzHrN7AMz22ZmpS4pnC2D1mdm\nHw7Z1mFmr5nZR9nvYZdJK6m3ZWa2N3vutpnZNSX1NtnM/tvM/mJm283snmx7qc9doq9SnreWv+w3\ns1GS/k/STyTtkfS2pPnu/peWNpLDzHolVdy99DlhM7tS0t8krXb3S7JtT0r61N2fyP7hPNvd72+T\n3pZJ+lvZKzdnC8pMGLqytKQ5km5Wic9doq+5KuF5K+PMP1PSLnf/xN2PSFov6foS+mh77v6GpE+/\ntfl6Sauy26s0+B9Py+X01hbcfZ+7v5vdPiTp+MrSpT53ib5KUUb4J0r665D7e9ReS367pD+Z2Ttm\ntrjsZoYxPls2XZL2SxpfZjPDqLlycyt9a2Xptnnu6lnxutH4wO+7Lnf3f5T0M0lLspe3bckH37O1\n03TNiFZubpVhVpb+WpnPXb0rXjdaGeHfK2nykPuTsm1twd33Zr/7JG1S+60+fOD4IqnZ776S+/la\nO63cPNzK0mqD566dVrwuI/xvS5pqZj80s+9Lmidpcwl9fIeZjc4+iJGZjZb0U7Xf6sObJS3Mbi+U\n9HKJvXxDu6zcnLeytEp+7tpuxWt3b/mPpGs0+In/x5IeKqOHnL7Ol/Re9rO97N4krdPgy8CjGvxs\n5DZJYyVtkfSRpP+S1NFGvf1B0geS3tdg0CaU1NvlGnxJ/76kbdnPNWU/d4m+Snne+IYfEBQf+AFB\nEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCOr/Aafwg6vBsdrbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}